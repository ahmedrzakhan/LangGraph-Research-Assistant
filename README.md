# LangGraph Research Assistant

A simple research assistant built with LangGraph that demonstrates core concepts for building stateful AI workflows.

**NEW:** Now with MCP (Model Context Protocol) integration for enhanced tool usage!

## What This Project Demonstrates

This project showcases the following concepts:

| Concept                | Implementation                                                      |
| ---------------------- | ------------------------------------------------------------------- |
| **State Management**   | `ResearchState` TypedDict defining shared state                     |
| **Node Functions**     | `planner_node`, `researcher_node`, `summarizer_node`                |
| **Graph Construction** | `StateGraph` with nodes and edges                                   |
| **Conditional Edges**  | `should_continue` function for dynamic routing                      |
| **Graph Compilation**  | `workflow.compile()` for execution                                  |
| **Visualization**      | `get_graph().draw_mermaid()` for diagram generation                 |
| **MCP Integration**    | Official MCP SDK (`mcp` package) for standardized tool access (NEW) |

---

## What is MCP (Model Context Protocol)?

MCP is a **standardized protocol** developed by Anthropic that enables LLMs to interact with external tools in a consistent, reusable way.

### Why MCP?

Think of MCP as a **"USB standard for AI tools"**:

| Problem                                   | MCP Solution                             |
| ----------------------------------------- | ---------------------------------------- |
| Every LLM app reimplements the same tools | Write once, use everywhere               |
| Tools are tightly coupled to applications | Tools are independent servers            |
| No standard for tool interfaces           | JSON-RPC based standard protocol         |
| Hard to share tools across projects       | Any MCP client works with any MCP server |

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Research Agent                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    LangGraph Workflow                    â”‚    â”‚
â”‚  â”‚   START â†’ planner â†’ researcher â†’ summarizer â†’ END       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â”‚ (when --mcp enabled)              â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                     MCP Client                           â”‚    â”‚
â”‚  â”‚   â€¢ Discovers available tools                            â”‚    â”‚
â”‚  â”‚   â€¢ Calls tools via JSON-RPC                            â”‚    â”‚
â”‚  â”‚   â€¢ Returns results to workflow                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    stdio transport     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MCP Server                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ web_search  â”‚  â”‚ get_facts   â”‚  â”‚  validate_claim     â”‚     â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚                     â”‚     â”‚
â”‚  â”‚ Search web  â”‚  â”‚ Get curated â”‚  â”‚ Check if claim is   â”‚     â”‚
â”‚  â”‚ for info    â”‚  â”‚ topic facts â”‚  â”‚ reasonable          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Setup

### 1. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure Environment Variables

```bash
cp .env.example .env
# Edit .env and add your Hugging Face token
# Get your token at: https://huggingface.co/settings/tokens
```

---

## Running the Assistant

### Without MCP (Original Mode)

```bash
python research_agent.py
```

### With MCP (Enhanced Mode)

```bash
python research_agent.py --mcp
```

When running with `--mcp`, the agent will:

1. Spawn the MCP server as a subprocess
2. Connect and discover available tools
3. Use MCP tools during the research phase
4. Display which tools are being called

---

## MCP Tools Available

| Tool             | Description                     | Input        | Output                                        |
| ---------------- | ------------------------------- | ------------ | --------------------------------------------- |
| `web_search`     | Search the web for information  | `query: str` | Search results with titles, snippets, sources |
| `get_facts`      | Get curated facts about a topic | `topic: str` | List of verified facts                        |
| `validate_claim` | Check if a claim is reasonable  | `claim: str` | Assessment with confidence score              |

---

## Example Output

### Without MCP

```
============================================================
ðŸ”¬ RESEARCH ASSISTANT
============================================================
Topic: artificial intelligence
ðŸ”Œ MCP Mode: DISABLED (use --mcp flag to enable)
============================================================

ðŸ“‹ PLANNER: Breaking down topic into key questions...
   Generated 3 research questions:
   â€¢ 1. What is artificial intelligence?
   â€¢ 2. How does machine learning work?
   â€¢ 3. What are the applications of AI?

ðŸ” RESEARCHER: Investigating each question...
   Researching question 1/3...
   âœ“ Question 1 answered
   ...
```

### With MCP

```
============================================================
ðŸ”¬ RESEARCH ASSISTANT
============================================================
Topic: artificial intelligence
ðŸ”Œ MCP Mode: ENABLED
ðŸ”Œ Using MCP tools: web_search, get_facts, validate_claim
============================================================

ðŸ“‹ PLANNER: Breaking down topic into key questions...
   Generated 3 research questions:
   â€¢ 1. What is artificial intelligence?
   â€¢ 2. How does machine learning work?
   â€¢ 3. What are the applications of AI?

ðŸ” RESEARCHER: Investigating each question...
   Researching question 1/3...
      ðŸ“¡ MCP: Calling web_search...
      ðŸ“¡ MCP: Calling get_facts...
      ðŸ“¡ MCP: Calling validate_claim...
   ðŸ” MCP Validation: LIKELY_VALID (confidence: 0.75)
   âœ“ Question 1 answered
   ...
```

---

## Project Structure

```
LangGraph-Research-Assistant/
â”œâ”€â”€ research_agent.py     # Main agent with MCP integration
â”œâ”€â”€ mcp_server.py         # MCP server with research tools
â”œâ”€â”€ mcp_config.json       # MCP configuration
â”œâ”€â”€ run_mcp_server.py     # Standalone server runner (optional)
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env.example          # Environment variable template
â””â”€â”€ README.md             # This file
```

---

## Code Deep Dive

### Before MCP (Original researcher_node)

```python
def researcher_node(state: ResearchState) -> dict:
    questions = state["questions"]
    llm = get_llm()

    answers = []
    for question in questions:
        # Just LLM call
        response = llm.invoke([...prompt with question...])
        answers.append(response.content)

    return {"answers": answers}
```

### After MCP (Enhanced researcher_node)

```python
def researcher_node(state: ResearchState) -> dict:
    questions = state["questions"]
    use_mcp = state.get("use_mcp", False)
    llm = get_llm()

    answers = []
    for question in questions:
        # If MCP enabled, gather additional context first
        if use_mcp and mcp_client.connected:
            # Call web_search for relevant information
            search_results = await mcp_client.call_tool("web_search", {...})
            # Call get_facts for curated facts
            facts = await mcp_client.call_tool("get_facts", {...})
            # Include in prompt...

        # LLM call with enriched context
        response = llm.invoke([...prompt with MCP context...])

        # Validate the answer
        if use_mcp:
            validation = await mcp_client.call_tool("validate_claim", {...})

        answers.append(response.content)

    return {"answers": answers}
```

---

## Key MCP Concepts Demonstrated

### 1. Tool Discovery

```python
# Client asks server: "What tools do you have?"
request = {"method": "tools/list"}
response = await mcp_client.send(request)
# Returns: [{"name": "web_search", ...}, {"name": "get_facts", ...}]
```

### 2. Tool Invocation

```python
# Client calls a tool
request = {
    "method": "tools/call",
    "params": {
        "name": "web_search",
        "arguments": {"query": "artificial intelligence"}
    }
}
result = await mcp_client.send(request)
```

### 3. Server Registration (using FastMCP)

```python
from mcp.server.fastmcp import FastMCP

# Create server instance
mcp = FastMCP("research-tools")

# Register tools using decorators - FastMCP handles schema generation
@mcp.tool()
def web_search(query: str) -> str:
    """Search the web for information."""
    return json.dumps({"results": [...]})

@mcp.tool()
def get_facts(topic: str) -> str:
    """Get curated facts about a topic."""
    return json.dumps({"facts": [...]})

# Run the server
mcp.run(transport="stdio")
```

---

## Configuration

Edit `mcp_config.json` to customize MCP behavior:

```json
{
  "mcpServers": {
    "research-tools": {
      "command": "python",
      "args": ["mcp_server.py"],
      "tools": [
        { "name": "web_search", "enabled": true },
        { "name": "get_facts", "enabled": true },
        { "name": "validate_claim", "enabled": true }
      ]
    }
  }
}
```

---

## Key Takeaways

1. **MCP separates tools from applications** - Write tools once, use them with any MCP-compatible LLM app

2. **Standardized protocol** - JSON-RPC based communication means consistent interfaces

3. **Easy extensibility** - Add new tools to the MCP server without changing the main agent

4. **Tool reusability** - The same MCP server could power Claude, GPT, or any other LLM

5. **Clean architecture** - The agent doesn't need to know how tools are implemented, just how to call them

---

## Extending This Project

Ideas for enhancement:

- Add more MCP tools (database queries, API calls, file operations)
- Implement HTTP/SSE transport for remote MCP servers
- Add authentication to MCP server
- Create parallel research with multiple MCP servers
- Add caching layer for MCP responses

---
